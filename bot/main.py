import os
import io
import time
import sqlite3
import numpy as np
import onnxruntime as rt
import telebot
from telebot.types import ReplyKeyboardMarkup
from sentence_transformers import SentenceTransformer
from PIL import Image
import torch

API_TOKEN = 'TELEGAM TOKEN'
MODEL_PATH = 'PATH TO MODEL'
Z_DIM = 100
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

DB_PATH = 'PATH TO DB'
os.makedirs('results', exist_ok=True)
conn = sqlite3.connect(DB_PATH, check_same_thread=False)
c = conn.cursor()
c.execute("""
CREATE TABLE IF NOT EXISTS generations (
    id        INTEGER PRIMARY KEY AUTOINCREMENT,
    user_id   INTEGER NOT NULL,
    timestamp TEXT    NOT NULL,
    prompt    TEXT    NOT NULL,
    file_path TEXT    NOT NULL
)
""")
conn.commit()

sess = rt.InferenceSession(MODEL_PATH)
embedder = SentenceTransformer('stsb-roberta-large')
bot = telebot.TeleBot(API_TOKEN)


def save_generation(user_id: int, prompt: str, img_buf: io.BytesIO):
    ts = time.strftime("%Y%m%d_%H%M%S")
    filename = f"{user_id}_{ts}.png"
    path = os.path.join('results', filename)
    with open(path, 'wb') as f:
        f.write(img_buf.getbuffer())
    c.execute(
        "INSERT INTO generations (user_id, timestamp, prompt, file_path) VALUES (?, ?, ?, ?)",
        (user_id, ts, prompt, path)
    )
    conn.commit()


def generate_image_buf(prompt: str) -> io.BytesIO:
    text_emb = embedder.encode(
        [prompt], convert_to_numpy=True).astype(np.float32)
    noise = np.random.randn(1, Z_DIM).astype(np.float32)
    fake = sess.run(None, {'text_emb': text_emb, 'noise': noise})[0]
    img_tensor = torch.tensor(fake[0], device=DEVICE)
    img_tensor = (img_tensor - img_tensor.min()) / \
        (img_tensor.max() - img_tensor.min())
    img = Image.fromarray(
        (img_tensor.permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8))
    buf = io.BytesIO()
    img.save(buf, format='PNG')
    buf.seek(0)
    return buf


@bot.message_handler(commands=['start'])
def on_start(msg):
    bot.send_message(
        msg.chat.id,
        "–ü—Ä–∏–≤–µ—Ç! –ß—Ç–æ–±—ã —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –Ω–∞–ø–∏—à–∏ –∑–∞–ø—Ä–æ—Å –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ."
        "\n–ù–∞–ø—Ä–∏–º–µ—Ä: \"Woman in a black pants\"."
    )


@bot.message_handler(func=lambda m: True)
def on_prompt_or_regenerate(msg):
    user_id = msg.chat.id
    text = msg.text.strip()

    if text == "üîÑ –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π":
        c.execute(
            "SELECT prompt FROM generations WHERE user_id = ? ORDER BY id DESC LIMIT 1",
            (user_id,)
        )
        row = c.fetchone()
        if not row:
            bot.send_message(user_id, "–£ –≤–∞—Å –ø–æ–∫–∞ –Ω–µ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.")
            return
        prompt = row[0]

        bot.send_message(
            user_id, f"–ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä—É—é –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å:\n¬´{prompt}¬ª‚Ä¶")
    else:
        prompt = text
        bot.send_message(user_id, f"–ì–µ–Ω–µ—Ä–∏—Ä—É—é –ø–æ –∑–∞–ø—Ä–æ—Å—É:\n¬´{prompt}¬ª‚Ä¶")

    try:
        buf = generate_image_buf(prompt)
        save_generation(user_id, prompt, buf)
        markup = ReplyKeyboardMarkup(resize_keyboard=True)
        markup.add("üîÑ –ü–µ—Ä–µ–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π")
        bot.send_photo(user_id, photo=buf, reply_markup=markup)
    except Exception as e:
        bot.send_message(user_id, f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")


print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
bot.polling(none_stop=True)
